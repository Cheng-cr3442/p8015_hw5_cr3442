---
title: "p8105_hw5_cr3442"
author: "Cheng"
date: "2024-11-15"
output: github_document
---
```{r load}
library(dplyr)
library(tidyr)
library(purrr)
library(broom)
library(ggplot2)
library(readr) # Ensure readr is loaded for read_csv function
library(stringr)
library(forcats)
```

## Problem 1
\
First simulate random birthdays and check for duplicate birthdays.
\
```{r}
# Simulate random birthdays and check for duplicates
birthday_simulation <- function(n) {
  birthdays <- sample(1:365, n, replace = TRUE)
  return(any(duplicated(birthdays)))
}
```
\
Then use functions to simulate the probability that at least two people in multiple groups have the same birthday.
\
```{r}
set.seed(123) # Ensure reproducibility
group_sizes <- 2:50
results <- sapply(group_sizes, function(n) {
  mean(replicate(10000, birthday_simulation(n)))
})
```
\
At last we output image.
\
```{r}
# Plot the probability as a function of group size
plot(group_sizes, results, type = "o", xlab = "Group Size", ylab = "Probability",
     main = "Relationship Between Group Size and Probability")
```
\
-----------------------------------------------------------------------------
\
## Problem 1
\
first power analysis through simulation.
\
```{r}
# Define the power simulation function
power_analysis <- function(mu, n = 30, sigma = 5, alpha = 0.05) {
  p_values <- replicate(5000, {
    data <- rnorm(n, mean = mu, sd = sigma)
    t_result <- tidy(t.test(data, mu = 0))
    t_result$p.value
  })
  power <- mean(p_values < alpha)
  return(power)
}

true_mus <- 0:6
power_results <- sapply(true_mus, power_analysis)
```
\
Then output image.
\
```{r}
# Plot the power curve
plot(true_mus, power_results, type = "o", xlab = "True Mean µ", ylab = "Power",
     main = "Relationship between True Mean µ and Power")

```
\
Then generate simulation results for mean estimation, compute the average estimated mean for each true mean, and compute the average estimated mean for the rejection of the null hypothesis.
\
```{r}
mu_estimates <- lapply(true_mus, function(mu) {
  replicate(5000, {
    data <- rnorm(30, mean = mu, sd = 5)
    t_result <- tidy(t.test(data, mu = 0))
    list(mu_hat = mean(data), p_value = t_result$p.value)
  }, simplify = FALSE)
})
# Compute the average estimated mean under each true mean
avg_mu_hat <- sapply(mu_estimates, function(sim_list) {
  mean(sapply(sim_list, function(x) x$mu_hat))
})

# Calculates the average estimated mean when the null was rejected 
avg_mu_hat_rejected <- sapply(mu_estimates, function(sim_list) {
# Filter out samples that reject the null
  rejected_samples <- Filter(function(x) x$p_value < 0.05, sim_list)
  if (length(rejected_samples) > 0) {
    mean(sapply(rejected_samples, function(x) x$mu_hat))
  } else {
    NA
  }
})
```
\
Finally we can plot the estimates.
\
```{r}
plot(true_mus, avg_mu_hat, type = "o", xlab = "True Mean µ", ylab = "Average µ Estimate",
     main = "Relationship between Average µ Estimate and True Mean µ")
lines(true_mus, avg_mu_hat_rejected, type = "o", col = "red")
legend("topleft", legend = c("All Samples", "Rejected Null Samples"), col = c("black", "red"), lty = 1)
```
\
-----------------------------------------------------------------------------
\
## Problem 3
\
First read in the data.
```{r}
# Read and clean the raw data
homicide_df = 
  read_csv("data/homicide-data.csv")%>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa, AL")
```
\
then summarize the total number of unsolved cases in each of the cities.
\
```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```
\
Next run prop.test for each of the cities in the dataset.
\
```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(prop_tests, broom::tidy)
  ) %>% 
  
# Extract both the proportion of unsolved homicides and the confidence interval for each
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```
\
Finally we can create a plot that shows the estimates and CIs for each city.
\
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion of Unsolved Homicides",
    caption = "Data Source: The Washington Post"
  )
```